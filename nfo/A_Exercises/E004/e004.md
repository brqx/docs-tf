<!-- Proyecto : # docs-tf -->
# Ejercicio E004 - Recordando Terraform - Realidad practica
# Ejercicio 04 : Puesta en marcha de una instancia EC2 en varios backends (s3)
# Latest Testing Apply : 22 - 02 - 2023

<!-- Nivel 2 E003 -  V0.0.1 - 2023 Feb -->

## Secciones

### A. Información previa para poder entender el proceso

Nuestro objetico ahora es poder acceder desde nuestra instancia EC2 a dos backends : 

a. S3
b. EFS

El primero es un acceso por API , ya que S3 son objetos. No es ninguna estructura de servidor, lo que se monta es una seudo-estructura de los mismos para genera un arbol de referencias

El segundo es nuestro conocido NFS pero en cloud

La idea es asociar un rol a nuestra instancia que permita acceder obtener un fichero y mostrarlo como salida de nuestro servidor http

No obstante este proceso no es trivial pues para ello necesitamos varios objetos

- Policy --> Politicas. Son definiciones de que se puede hacer con un objeto. Por defecto : Nada               \
- Roles  --> Una manera de dar permiso a un objeto o servicio para hacer algo con otra entidad de la nube      \
- Instance Profiles --> Una forma de asociar estos permisos con una instancia Ec2

### B. Aspectos relacionados con S3

bucket_name       --> Nombre del bucket unico a nivel mundial pero localizado en una REGION    \
sid               --> Nombre opcional identificativo de la politica de S3

No vamos a crear un bucket ya que queremos acceder a un contenido existente en el mismo

Entonces vamos a acceder a el de varias formas

La primera con la API de AWS

La segunda con una sistema de ficheros especifico para S3 llamado s3fs

### B. Aplicación - Ejecución del Plan

Ejecutando un Apply podemos ver las salidas de este primer boceto : 

```
common_tags = {
  "Environment" = "dev"
  "Project" = "RMB-TF-E001"
}
prefix = "amazon-exercises-terraform"
region = "eu-west-1"
```

De momento sólo creando esta infraestructura los tiempos son los siguientes : 

```
s3_bucket = "fz3"
vpc_cidr = "10.20.0.0/16"
vpc_id = "vpc-0a6aacc7106929196"

real    0m45.107s

Destroy complete! Resources: 11 destroyed.

real    1m15.679s

```

Vemos que tarda rondando el minuto en crear y destruir. hay que esperar un poquito para que arranque al tener al conexion a s3 en el inicio

Nos conectamos a nuestra EC2 : 

aw2s IP

```
aws sts get-caller-identity
{
    "Account": "xxx9687099", 
    "UserId": "xxxxxFUXA56F7HGQVD7:i-0101eaa7d6bc81d69", 
    "Arn": "arn:aws:sts::xxx9687099:assumed-role/ec2-to-s3-access/i-0101eaa7d6bc81d69"
}
```

Al ejecutar este comando podemos ver que el rol esta correctamente aplicado

Vamos a ver los recursos s3 : 

```
aws s3 ls s3://fz3/test/
2023-01-30 13:28:46          0 
2023-01-30 13:31:03         36 file_file_from_s3.dat
```

Podemos ver el fichero a recuperar

```
curl IP
Hi Friend of brqx , I am ip-10-20-1-49.eu-west-1.compute.internal hosted by Terraform
Este es el contenido de S3: Este fichero viene de S3. 2023 AA1 
```

Al tener que conectarse a S3 tarda un poco mas en arrancar, pero es capaz de recupear nuestra informacion como vemos.

### C. Enlaces de infraestructura
 
@providers.tf  (Definido en E000)             @backend.tf     (Definido en E000)   \         
@vpc.tf        (Definido en E000)             @public_subnets (Definido en E001)   

### D. Enlaces de informacion 


@main.tf       (Definido en E000)             @variables.tf  (Definido en E000)             \
@maps.tf       (Definido en E000)             

### E. Enlaces de EC2

@ami            (Definido en E001)             \
@ec2_sg         (Definido en E002)             

### F. Cambios en Ficheros

output.tf     -->  Fichero de salida. Indica las instancias usables cuando se quiera usar este estado      \
main.tf       -->  Fichero principal del proyecto, donde se recupera el estado y se actua                  

### G. Nuevos Ficheros

ec2_ip_s3.tf  -->  Fichero de EC2 con una configuracion de Instance Profile                                \
ec2_tf_s3.tf  -->  Fichero template para S3                                                                \
s3_full.tf    -->  Fichero con la información del Bucket S3, Roles y políticas para ser accedido por EC2   

### H. Comandos

ti --> Terraform Init                  \
tv --> Terraform Validate              \
tp --> Terraform Plan                  \
tta --> Terraform Apply                \
ttd --> Time Terraform Destroy         

### I. Grafico

Vamos a ver lo que hemos definido. Fijaos que para lo poquito que es: VPC { Subnet[AZ] } ,Ec2 y S3. 

Requiere bastante código y diferentes ficheros para tener una estructura organizada

```
[[VPC - 10.20.0.0/16         - 64k hosts]] ------------------------------------------------------------
   I  [Subnet - 10.20.1.0/24 - 256 hosts ] - - - - - -- - - - - - - - - I
        I  [EC2(a.b.c.d) - Public IP ] -- instance_profile -> [ S3(bucket) ] I
                                            |-- rol 
                                            |-- policy
```

<!-- ==--==--==--==--==--==--==--==--==--==--==--==--==--==--==-- -->

## Referencias (Pendiente)

https://ao.ms/solved-error-acquiring-the-state-lock-in-terraform/
https://www.sammeechward.com/s3-and-iam-with-terraform  --> Acceso a S3 desde EC2
https://registry.terraform.io/providers/hashicorp/aws/latest/docs/data-sources/s3_bucket
https://github.com/meech-ward/sammeechward.com_mdx/blob/master/content/articles/aws/s3-and-iam-with-terraform/index.mdx
https://cloudkul.com/blog/mounting-s3-bucket-linux-ec2-instance/ --> Acceso a S3FS desde EC2
https://discuss.hashicorp.com/t/terraform-0-14-local-source-invalid-function-argument/18624/3
https://cloudsbaba.com/how-to-mount-s3-bucket-with-ec2-linux-instance-using-iam-roles/   --> Acceso a S3FS desde EC2



